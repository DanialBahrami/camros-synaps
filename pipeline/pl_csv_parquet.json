{
	"name": "pl_csv_parquet",
	"properties": {
		"activities": [
			{
				"name": "Get File Names",
				"type": "GetMetadata",
				"dependsOn": [],
				"policy": {
					"timeout": "0.12:00:00",
					"retry": 0,
					"retryIntervalInSeconds": 30,
					"secureOutput": false,
					"secureInput": false
				},
				"userProperties": [],
				"typeProperties": {
					"dataset": {
						"referenceName": "ds_adls_edp_raw_folder",
						"type": "DatasetReference"
					},
					"fieldList": [
						"childItems"
					],
					"storeSettings": {
						"type": "AzureBlobFSReadSettings",
						"recursive": true,
						"enablePartitionDiscovery": false
					},
					"formatSettings": {
						"type": "BinaryReadSettings"
					}
				}
			},
			{
				"name": "For Each File",
				"type": "ForEach",
				"dependsOn": [
					{
						"activity": "Get File Names",
						"dependencyConditions": [
							"Succeeded"
						]
					}
				],
				"userProperties": [],
				"typeProperties": {
					"items": {
						"value": "@activity('Get File Names').output.childItems",
						"type": "Expression"
					},
					"isSequential": true,
					"activities": [
						{
							"name": "Notebook Spark CSV to Parquet",
							"type": "SynapseNotebook",
							"dependsOn": [],
							"policy": {
								"timeout": "0.12:00:00",
								"retry": 0,
								"retryIntervalInSeconds": 30,
								"secureOutput": false,
								"secureInput": false
							},
							"userProperties": [],
							"typeProperties": {
								"notebook": {
									"referenceName": "spark_csv_parquet_england",
									"type": "NotebookReference"
								},
								"parameters": {
									"filename": {
										"value": {
											"value": "@item()['name']",
											"type": "Expression"
										},
										"type": "string"
									}
								},
								"snapshot": true,
								"sparkPool": {
									"referenceName": "sparkpoolshs",
									"type": "BigDataPoolReference"
								},
								"executorSize": "Small",
								"conf": {
									"spark.dynamicAllocation.enabled": null,
									"spark.dynamicAllocation.minExecutors": null,
									"spark.dynamicAllocation.maxExecutors": null
								},
								"driverSize": "Small",
								"numExecutors": null
							}
						}
					]
				}
			}
		],
		"annotations": []
	}
}